# ğŸ“¸ Multimodal Image RAG  
**AWS Bedrock (Titan) + ChromaDB + OpenAI Vision**

This repository contains a **from-scratch, production-aware implementation** of a **multimodal image retrieval pipeline** (Image RAG).

It demonstrates how to:

- Download images from **Amazon S3**
- Create **multimodal embeddings** using **Amazon Bedrock Titan**
- Store vectors in **ChromaDB**
- Retrieve images using **natural language queries**
- (Optionally) generate **vision-based summaries** using **OpenAI models**
- Handle failures and corrupted images gracefully

This project is implemented as a **Colab-friendly Python notebook**, but structured so the logic can be reused in production systems.

---

## ğŸ§  High-Level Architecture

### Ingestion (one-time or periodic)
```
S3 Images
   â†“
Download to local disk
   â†“
Normalize images (JPEG, RGB, resize)
   â†“
Titan Multimodal Image Embeddings
   â†“
ChromaDB (persistent vector store)
```

### Retrieval (per query)
```
User text query
   â†“
Titan Text Embedding
   â†“
Chroma similarity search
   â†“
Top-K images (with distances)
```

### Optional Generation (Vision)
```
Top images
   â†“
OpenAI Vision model
   â†“
Human-readable summary (S1â€¦Sn references)
```

---

## âœ¨ Key Features

- âœ… True multimodal search (text â†’ image)
- âœ… Shared embedding space (Titan text + image)
- âœ… Failure-tolerant ingestion
- âœ… Cost-aware design (embed once, reuse forever)
- âœ… Colab-ready
- âœ… Production-portable logic

---

## ğŸ“ Project Structure (Recommended)

```
.
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ image_rag_poc.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ images/              # downloaded S3 images
â”œâ”€â”€ chroma_images_db/        # Chroma persistent storage
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ image_rag_docs.html
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ” Prerequisites

### AWS
- S3 bucket with images (`.jpg`, `.jpeg`, `.png`)
- IAM user with:
  - `s3:GetObject`
  - `s3:ListBucket`
  - `bedrock:InvokeModel`
- Environment variables:
```bash
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
AWS_DEFAULT_REGION
```

### OpenAI (optional)
```bash
OPENAI_API_KEY
```

---

## ğŸ” Typical Usage Flow

```python
# 1. List images in S3
image_keys = list_image_keys(BUCKET, PREFIX, max_keys=200)

# 2. Download locally
local_paths = download_s3_objects(BUCKET, image_keys)

# 3. Build stable records
records = build_image_records(image_keys, local_paths)

# 4. Create / load Chroma collection
collection = get_chroma_collection()

# 5. Embed + upsert
failed = upsert_images_to_chroma(collection, records)

# 6. Query
hits = query_images(collection, "blue t-shirt", k=8)

# 7. Display
show_hit_images(hits, s3_to_local)
```

---

## ğŸ§© Core Functions (Summary)

### S3 Utilities
- `get_s3_client()` â€“ Create S3 client
- `list_image_keys()` â€“ List image keys from S3
- `download_s3_objects()` â€“ Download images locally

### Image Processing
- `normalize_image_to_jpeg_bytes()` â€“ Normalize images to safe JPEG bytes

### Bedrock Embeddings
- `titan_embed_image_safe()` â€“ Image embeddings
- `titan_embed_text()` â€“ Text embeddings

### Vector Store
- `get_chroma_collection()` â€“ Create/load ChromaDB
- `upsert_images_to_chroma()` â€“ Batch embedding + upsert

### Retrieval & Display
- `query_images()` â€“ Text â†’ image similarity search
- `show_hit_images()` â€“ Display retrieved images

### OpenAI Vision (Optional)
- `image_to_b64()` â€“ Encode image for OpenAI
- `summarize_images_with_openai()` â€“ Vision-based summaries

---

## ğŸ’¸ Cost Awareness

- **Titan embeddings**: one-time cost per image
- **Text queries**: very low cost
- **ChromaDB**: free (local)
- **OpenAI Vision**: pay per request (optional)

ğŸ‘‰ Best practice: embed once, reuse forever.

---

## ğŸš€ Roadmap / Extensions

- OCR + text indexing
- Metadata filters
- Re-ranking with vision models
- Video â†’ frame â†’ image RAG
- Managed vector store (OpenSearch / pgvector)

---

## ğŸ“„ License

MIT (or your preferred license)
